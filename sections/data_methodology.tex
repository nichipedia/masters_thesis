\section{Data Methodology}
\setlength{\parindent}{10ex}

All feature data used in this work was aggregated from existing studies.
All features and their origin datasets can be seen in the table \ref{table:FEATURE_LIST}. %Insert point to figure yadaydada
The ETOPO dataset was used for bathymetry values.
This dataset contains predicted bathymetry with sparsely populated \ac{MBES} soundings.

%This section is for defining the data being used in the experiment
%It should define where the data came from and its format
%I can also explain any of the special stuff I am doing (Binning for example)
%

\begin{table}[htb]
    \centering
    \begin{tabular}{ |p{0.5\textwidth} p{0.5\textwidth}| }
        \hline
            \textbf{Feature} & \textbf{Origin Study} \\
            \hline
            Mantle Density & CRUST1 \cite{laske2013update} \\
            LAND One Hot & ETOPO \cite{national1988etopo} \\
            Crust Thickness & CRUST1 \cite{laske2013update} \\
            Low, Mid, High Crust Density & CRUST1 \cite{laske2013update} \\
            Estimated Current East, North, Mag & HYCOM \cite{chassignet2009us} \\
            Sea Nitrate, Phosphate, Salinity Measurements & NASA Studies \cite{meissner2018salinity} \cite{parekh2005decoupling}  \\
            Sea Temperature, Silicate Measurements & NASA Studies \\
            Sediment Thickness & CRUST1 \cite{laske2013update} \\
            BioMass Features & \cite{wei2010global} \\
            Geoid Features & EGM \cite{pavlis2008earth} \\
            Wave height, period & WAVEWATCH \cite{tolman20072007} \\
        \hline
    \end{tabular}
    \label{table:FEATURE_LIST}
    \caption{List of Ocean Features used in Models for this Project.}
\end{table}
%I am using this section to introduce the feature selection method that I preformed
%Maybe I can flesh this out more and talk about it in def??
%Maybe make a diagram for the flow of the GA?
\subsection{Feature Selection}
Feature selection was used to identify the most relevant features for classification.
This important step in the \ac{ML} pipeline removes noise from irrelevant data.
This work used a genetic algorithm approach for feature selection \cite{yang1998feature}.
Other approaches that were considered included a grid search, dimensional analysis, and simple variable correlations.
These approaches were found to either take too long or simply not offer enough improvement to the model.
Where as the genetic algorithm approach gave relatively quick model improvements with little effort.
See figure \ref{fig:GA} for an illustration of a generic genetic algorithm.

\par
Using a genetic algorithm for feature selection is a simple application of the original process.
The initialized population is a set of random binary strings.
Each string has a character length equal to the number of features in our feature space.
The binary characters represent whither a feature is active or inactive.
Essentially these strings represent a set of features to use in training a model.
The fitness of that string is represented by the resulting model's accuracy.
Selection is performed by choosing the most accurate models and their characteristics are passed to the next generation.
A simple crossover mutation of the strings is used along with a modest 5\% mutation rate.
Upon termination the resulting fittest string is used as the selected features.


\begin{figure}[h]
    \centering
    \caption{Diagram of Generic Genetic Algorithm}
    \label{fig:GA}
    \includegraphics[scale=0.5]{genetic_algorithm.png}
\end{figure}

\par
Feature selection was used to remove noise from the training data.
This down sizing happened at a global scale.
It is possible that this may affect localized predictions where a feature is a strong predictor.
This was not tested in this work, but is a intersting question.
Identifying locally optimum features could lead to better models.


%This decribes how the grid files are used and oragnized...
%They are essentially binary files...
\subsection{Data Representation}
Global data is typically represented in a grid formatted where each grid represents a coverage of the Earth's surface.
This representation is an average of the data across the coverage of that cell, but is not guaranteed.
The data used in this work has been organized into a grid for ease of use and human readability.
Each grid represents a cell centered data point and they are organized into a EPSG:3857 \ac{CRS}.

\par
The spatial resolution of a grid defines its coverage.
This spatial resolution can be described as the height and width of a grid.
This height and width is not physically constant.
For example, a cell at the equator is larger and covers more physical area than a cell at the poles.
However, this is the best way to represent the data in a consistent and structured manner.

\par
All data in this project has been organized into two minute bathymetry grids.
A two minute bathymetry grid has a spatial resolution of 0.034 degrees per cell, which is approximately 3 kilometers of spatial coverage.
The grids have a column length of 5400 and a row width of 10800.

\par
This resolution was chosen for experiments to conserve memory and time.
Larger grids have a exponentially larger memory and computational footprint.
I used the \ac{ETOPO}2v2 \cite{national1988etopo} dataset as the source of the two minute bathymetry grid.
Finer resolution datasets exist, such as the SRMT30 \cite{becker2009global} at 30 second resolution.
In any event, the two minute resolution offered a good balance of memory, accuracy, and computational costs.

\subsection{Ocean Features}
Similar to bathymetry values, all extracted ocean features for this project were organized into a two minute bathymetry grid.
They were aggregated from several projects.
Absent data points were either interpolated, or filled with default values.
See table \ref{table:FEATURE_LIST} for a complete list of all features.

\par
Figure \ref{fig:bathyxfish} shows the relationship between estimated fish biomass and bathymetry.
It can be conjectured that this relationship is more corelation that causality.
For example, biomass increases are not caused by shallow depths.
The shallow depth has more available light which allows for vegatation and energy supplies for more species.
This could explain the relationship show in the graph in figure \ref{fig:bathyxfish}


\par
Figure \ref{fig:bathyxdensity} shows an example of a inverse relationship to bathymetry.
This relationship may be more of a causality relationship than correlation.
Denser crust is caused by many different factors that are seperate from bathymetry.
It is possible that deeper water columns and the resulting weight contributed, but it can not be used to describe the correlation of the variables.

\par
In general, the features used in this project were a grab bag of potential predictors.
Features such as estimated oxygen, nitrogen, salinity, etc make sense for being related to bathymetry.
Where other features such as crust density may not naturally be explained.
The feature selection was used to identify the best preforming features.
Future study in the relationship of these features and how they benefit predicting bathymetry will be nessassary.

%\ref{fig:pairplot} Shows a pair plot of all the features used in training.
%The diagonal in the pair plot will show the correlation of point distributions in each individual plot.
%Each of the discussed plots were taken from data in the south Pacific ocean.
%This was done as a isolated demonstration of the data.
%Talk about the plots here and include them once seaborn has decided to stop being dumb...

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{Bathymetry_X_SS_BIOMASS_FISH_LOG10_MGCM2_Wei2010x.png}
    \caption{Graph of Bathymetry and Estimated Fish BIOMASS}
    \label{fig:bathyxfish}
\end{figure}

%\begin{figure}[h]
%    \centering
%    \includegraphics[scale=0.5]{Bathymetry_X_SS_BIOMASS_MEGAFAUNA_LOG10_MGCM2_Wei2010x.png}
%    \caption{Graph of Bathymetry and Estimated MegaFauna Bio Mass}
%    \label{fig:bathyxfauna}
%\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{Bathymetry_X_SS_DENSITY_KGM-3_SACD_Aquarius_MISSION_MEANx.png}
    \caption{Graph of Bathymetry and Estimated Crust Density}
    \label{fig:bathyxdensity}
\end{figure}

%\begin{figure}[h]
%    \centering
%    \includegraphics[scale=0.5]{pairplot.png}
%    \caption{Pair Plot of All Features Used in Training}
%    \label{fig:pairplot}
%\end{figure}

%Maybe I can talk about some of the correlations I preformed here???? A few graphs perhaps???
%Maybe talk about the PCC???
%Possibly need to talk about the breadth of features here....

\subsection{Bathymetry Values}
ETOPO2v2 is used for the bathymetry soundings \cite{national20062}.
This extension of the ETOPO2 dataset \cite{national1988etopo} is a more accurate and updated version of the ETOPO2 dataset.
Specifically, this version eliminates a westward bias present in the original version.
The two minute \ac{ETOPO} dataset was used to match the chosen resolution for this work.
\ac{ETOPO} was aggregated by the \ac{NGDC} which is a department of \ac{NOAA}.

\par
Land topography is included in the \ac{ETOPO} dataset.
This proved to be problematic in making ocean predictions.
Therefore, a mask was created to remove the land topography in all training datasets.
This is applied to the data before training to ensure that land data is not used in training.

%There is a better was to describe why the features were binned like this
%I want to describe the value that was added by binning my data into classes!
\par
The classification performed in this work used binned bathymetry from \ac{ETOPO}.
These classes were partitioned on a interval of 150 meters.
This partitioning scheme was chosen to compare to the results from a similar project \cite{jena2012prediction}.
The binning is performed to test the viability of converting bathymetry prediction into a classification problem.